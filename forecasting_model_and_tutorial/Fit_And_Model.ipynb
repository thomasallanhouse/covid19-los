{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at Outcomes from Ward with Covariates\n",
    "\n",
    "Use the multi-state model to look at outcomes by age.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import required packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "import scipy.special as sp\n",
    "import scipy.optimize as op\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy import integrate\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import pymc3 as pm\n",
    "import random\n",
    "import arviz as az\n",
    "from datetime import datetime, date\n",
    "from datetime import timedelta\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define input variables. All variable should hopefully be here, so after adjusting these each week,\n",
    "#### the code can hopefully be run without making further adjustments.\n",
    "\n",
    "###### What date did we extract the data?\n",
    "file_date = 'simulated_30May' # Update to the date format used for the input files\n",
    "dtpull = date(2020,5,27) # update to extract date, best to use 2 days prior to current date\n",
    "cur_date = dtpull # Tell the code that the current date is the date of the last included admission, rather than today.\n",
    "forecast_start = date(2020,5,30) # Enter the date we want forecasts to start, for GM aggregate use Tuesday of each week.\n",
    "######\n",
    "\n",
    "###### Growth rate and initial conditions for daily admissions trend\n",
    "admissions_conditions = pd.read_csv('admissions_conditions_'+file_date+'.csv') # load admissions trends\n",
    "I0_0 = admissions_conditions.initial_value.values[0] # current expected number of admissions: age group 0\n",
    "rate_0 = admissions_conditions.out_mean.values[0] # growth rate of admissions: age group 0 \n",
    "I0_1 = admissions_conditions.initial_value.values[1] # current expected number of admissions: age group 1\n",
    "rate_1 = admissions_conditions.out_mean.values[1] # growth rate of admissions: age group 1\n",
    "I0_2 = admissions_conditions.initial_value.values[2] # current expected number of admissions: age group 2\n",
    "rate_2 = admissions_conditions.out_mean.values[2] # growth rate of admissions: age group 2\n",
    "I0_3 = admissions_conditions.initial_value.values[3] # current expected number of admissions: age group 3\n",
    "rate_3 = admissions_conditions.out_mean.values[3] # growth rate of admissions: age group 3 \n",
    "rate_overall = admissions_conditions.out_mean.values[4] # growth rate of admissions across all age groups\n",
    "######\n",
    "\n",
    "###### Approximating age groups using the all age group growth rate?\n",
    "###### This is useful is we have insufficient data to fit growth rates for some of the age groups\n",
    "approx_growth = False # Set to true if this is required\n",
    "######\n",
    "\n",
    "###### Which age groups go to ICU?\n",
    "ICU_0 = True # any 0-25 patients go to ICU?\n",
    "ICU_1 = True # any 26-50 patients go to ICU?\n",
    "ICU_2 = True # any 51-75 patients go to ICU?\n",
    "ICU_3 = True # any 76+ patients go to ICU?\n",
    "######\n",
    "\n",
    "###### How many samples/simulation should we run? As high as possible is best, but increases computational time\n",
    "nboot = 100 # specify number of sample to draw from MCMC posterior. The more samples used gives a better representation\n",
    "npat = 1000 # specify number of patients to simulate for posterior credibility\n",
    "######\n",
    "\n",
    "###### How many MCMC samples should be test? Again, as high as possible is best\n",
    "draw_num = 1500 # number of iterations to keep\n",
    "tune_num = 2500 # number of run in iterations to burn\n",
    "######\n",
    "\n",
    "###### How many independent chains should we run and how many cores can we use?\n",
    "chain_num = 1 # number of independent chains to run\n",
    "core_num  = 4 # number of cores to use, must be less than or equal to chain_num\n",
    "######\n",
    "\n",
    "###### Do we have saved MCMC traces? This enables the forecast to be rerun without fitting the data each week.\n",
    "## This can be useful as the fitted distributions are unlikely to change much each week.\n",
    "saved = 0 # load saved trace into xhats variable instead of running a new sample\n",
    "######\n",
    "\n",
    "###### Do we want to use combination of Burr and Weibull or just Weibull. If sample size is very small, just Weibull might be best\n",
    "global_dist = 0 # If \"1\" use a single distribution for all transitions, otherwise use combination of Burr and Weibull\n",
    "######\n",
    "\n",
    "generate_los_estimates = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Load data - start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load length of stay data and census data\n",
    "\n",
    "df = pd.read_csv('Current_COVID_'+file_date+'.csv')\n",
    "\n",
    "census_covariates = pd.read_csv('census_covariates_'+file_date+'.csv').values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Load data - end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Define states and transitions - start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_names = (\n",
    "    \"Acute Ward\",\n",
    "    \"ICU\",\n",
    "    \"Recovery Ward\",\n",
    "    \"Discharge\",\n",
    "    \"Death\",\n",
    ")\n",
    "nstates = len(state_names)\n",
    "\n",
    "allowed_transitions = (\n",
    "    (\"Acute Ward\", \"ICU\"),\n",
    "    (\"Acute Ward\", \"Discharge\"),\n",
    "    (\"Acute Ward\", \"Death\"),\n",
    "    (\"ICU\", \"Recovery Ward\"),\n",
    "    (\"ICU\", \"Death\"),\n",
    "    (\"Recovery Ward\", \"Discharge\"),\n",
    ")\n",
    "ntrans = len(allowed_transitions)\n",
    "\n",
    "state_dict = {state: loc+1 for loc, state in enumerate(state_names)}\n",
    "state_name_dict = {loc+1: state for loc, state in enumerate(state_names)}\n",
    "IJ = [(state_dict[xy[0]],state_dict[xy[1]]) for xy in allowed_transitions]\n",
    "DG = nx.DiGraph()\n",
    "DG.add_edges_from(IJ)\n",
    "plt.figure(figsize=(5,5))\n",
    "pos=nx.circular_layout(DG)\n",
    "nx.draw(DG,pos)\n",
    "nx.draw_networkx_labels(DG,pos,labels=state_name_dict)\n",
    "plt.show()\n",
    "\n",
    "Qbase = nx.to_numpy_array(DG,dtype='int',nodelist=range(1,nstates+1))\n",
    "Qbase # Matrix of allowed transitions: G[i,j] is from i to j\n",
    "\n",
    "nxy = np.shape(Qbase)\n",
    "TransNum = Qbase.copy()\n",
    "k=1\n",
    "for i in range(0,nxy[0]):\n",
    "    for j in range(0,nxy[1]):\n",
    "        if (Qbase[i,j] > 0):\n",
    "            TransNum[i,j] = k\n",
    "            k +=1\n",
    "TransNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Define states and transitions - end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Define required functions - start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Return a Weibull scale parameter from the linear predictor\n",
    "def get_scale(x, k=1.0, ATF=True):\n",
    "    if ATF:\n",
    "        return np.exp(-x)\n",
    "    else:\n",
    "        return np.exp(-x/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define function for simulating indicative scenarios over the next few months\n",
    "def indicative_simulator(scenario,nboot): # scenario is 1 (exponential growth) or 0 (constant admissions)\n",
    "    #### Define age indicator variable and add the variable group names\n",
    "    aci = (\n",
    "        (0),\n",
    "        (1),\n",
    "        (2),\n",
    "        (3)\n",
    "        )\n",
    "    anam = (\n",
    "        'Under 26',\n",
    "        '26-50',\n",
    "        '51-75',\n",
    "        'Over 75'\n",
    "    )\n",
    "    distribution = \"weibull\"\n",
    "    na = len(aci) # number of age groups considered\n",
    "    ld = len(census_covariates)\n",
    "    dextra = 50\n",
    "    ldd = ld + dextra\n",
    "    dayrange = range(1,ldd+1)\n",
    "    output = np.zeros((na,nboot,nstates,ldd))\n",
    "    counts = np.zeros((nboot,nstates,ldd))\n",
    "    for jj in tqdm(range(0,na)):\n",
    "        census = census_covariates[:,jj*(nstates+1):(jj+1)*(nstates+1)]\n",
    "        counts = np.zeros((nboot,nstates,ldd))\n",
    "        print(\"Ensure that growth rates and initial conditions are updated for your local admission trends\")\n",
    "        if (scenario == 1): \n",
    "            vect = np.array(range(1,dextra+1)) # vector counting number of days of exponential growth\n",
    "            if (jj==0): \n",
    "                I0 = I0_0 # current expected number of admissions\n",
    "                rate = rate_0 # growth rate in admissions\n",
    "                aa = I0*np.exp((rate)*vect) # construct vector of expected number of admissions per day\n",
    "            elif (jj==1):\n",
    "                I0 = I0_1 # current expected number of admissions\n",
    "                rate = rate_1 # growth rate in admissions\n",
    "                aa = I0*np.exp((rate)*vect) # construct vector of expected number of admissions per day\n",
    "            elif (jj==2):\n",
    "                I0 = I0_2 # current expected number of admissions\n",
    "                rate = rate_2 # growth rate in admissions\n",
    "                aa = I0*np.exp((rate)*vect) # construct vector of expected number of admissions per day\n",
    "            elif (jj==3):\n",
    "                I0 = I0_3 # current expected number of admissions\n",
    "                rate = rate_3 # growth rate in admissions\n",
    "                aa = I0*np.exp((rate)*vect) # construct vector of expected number of admissions per day\n",
    "                \n",
    "            if approx_growth: # approximate the growth rate using the growth rate across all ages if necessary\n",
    "                rate = rate_overall\n",
    "                aa = I0*np.exp((rate)*vect) # construct vector of expected number of admissions per day\n",
    "\n",
    "        else:\n",
    "            if (jj==0):\n",
    "                aa = I0_0 # number of 0-25 admissions per day\n",
    "                aa = np.mean(census[-10:,5])\n",
    "            elif (jj==1):\n",
    "                aa = I0_1 # number of 26-50 admissions per day\n",
    "                aa = np.mean(census[-10:,5])\n",
    "            elif (jj==2):\n",
    "                aa = I0_2 # number of 51-75 admissions per day\n",
    "                aa = np.mean(census[-10:,5])\n",
    "            elif (jj==3):\n",
    "                aa = I0_3 # number of 76+ admissions per day\n",
    "                aa = np.mean(census[-10:,5])\n",
    " \n",
    "        index_other = aci[jj]+8\n",
    "        index_shape = aci[jj]+4\n",
    "        index_scale = aci[jj]\n",
    "        for s in tqdm(range(0,nboot)):\n",
    "            ind = random.randint(0,chain_num*draw_num-1)\n",
    "            kmatb = np.zeros((nstates,nstates)) \n",
    "            scalematb = np.zeros((nstates,nstates))\n",
    "            othermatb = np.zeros((nstates,nstates))\n",
    "            for k in range(0,ntrans):\n",
    "                if not global_dist: \n",
    "                    if (k==3 or k==4 or k==5):# If we don't assume a global distribution, fit combination of distributions\n",
    "                        distribution = \"weibull\" # Fit ICU to death and ICU to recovery using Weibull distributions\n",
    "                    else:\n",
    "                        distribution = \"burr\" # Fit remaining transitions using Burr distributions\n",
    "                if (distribution == \"weibull\"):\n",
    "                    ij = np.argwhere(TransNum == (k+1))[0]\n",
    "                    kmatb[ij[0],ij[1]] = (xhats[k,index_shape,ind])\n",
    "                    scalematb[ij[0],ij[1]] = get_scale(xhats[k,index_scale,ind])\n",
    "                    othermatb[ij[0],ij[1]] = float('nan')\n",
    "\n",
    "                if (distribution == \"burr\"):\n",
    "                    ij = np.argwhere(TransNum == (k+1))[0]\n",
    "                    kmatb[ij[0],ij[1]] = (xhats[k,index_shape,ind])\n",
    "                    scalematb[ij[0],ij[1]] = (xhats[k,index_scale,ind])\n",
    "                    othermatb[ij[0],ij[1]] = (xhats[k,index_other,ind])\n",
    "\n",
    "                if not (distribution == \"burr\" or distribution == \"weibull\"):\n",
    "                    print(\"Not fitting correct distribution - please use Weibull or Burr\")\n",
    "                    exit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            adm = np.zeros(ldd) \n",
    "            adm[0:len(census[:,5])] = census[:,5] # admissions\n",
    "            \n",
    "            ### Add noise to admissions data by assuming drawn from a poisson distribution about the expected value\n",
    "            if (scenario ==0):\n",
    "                adm[len(census[:,5]):] = np.random.poisson(lam=aa,size=dextra)\n",
    "            else:\n",
    "                adm[len(census[:,5]):] = np.random.poisson(lam=aa)\n",
    "            ###\n",
    "\n",
    "            for d in dayrange:      \n",
    "                for i in range(0,int(adm[d-1])):\n",
    "                    y=0\n",
    "                    Yi = np.array([y])\n",
    "                    Ti = np.array([0.0])\n",
    "                    while ((np.sum(Qbase[y,:]) > 0.0) and (Ti[-1]<=ldd)):\n",
    "                        zz = np.where(Qbase[y,:] > 0.0)[0]\n",
    "                        tti = np.zeros(len(zz))\n",
    "                        yyi = np.zeros(len(zz))\n",
    "                        for q, z in enumerate(zz):\n",
    "                            if np.isnan(othermatb[y,z]): # If transition is given by Weibull\n",
    "                                k = kmatb[y,z]\n",
    "                                scaleg = scalematb[y,z]\n",
    "                                if np.isnan(k):\n",
    "                                    tti[q] = float('inf') # if transition not observed, set to inf to it can't take place\n",
    "                                else:\n",
    "                                    tti[q] = scaleg*np.random.weibull(k)\n",
    "                                yyi[q] = z\n",
    "                            else:          # If transition is given by Burr\n",
    "                                k = kmatb[y,z]\n",
    "                                scaleg = scalematb[y,z]\n",
    "                                otherp = othermatb[y,z]\n",
    "                                if np.isnan(k):\n",
    "                                    tti[q] = float('inf') # if transition not observed, set to inf to it can't take place\n",
    "                                else:\n",
    "                                    tti[q] = st.burr12.rvs(otherp, k, scale = scaleg)\n",
    "                                yyi[q] = z                                           \n",
    "\n",
    "                        r = np.argmin(tti)\n",
    "                        tran = TransNum[y,:][np.nonzero(TransNum[y,:])][r]\n",
    "                        y = int(yyi[r])\n",
    "                        Yi = np.append(Yi,y)\n",
    "                        Ti = np.append(Ti,Ti[-1].copy() + tti[r])\n",
    "                    Zi = [int(np.round(x)) for x in Yi]\n",
    "                    Di = [(d + int(np.round(x))) for x in Ti]\n",
    "                    for m in range(0,len(Di)):\n",
    "                        j = Zi[m]\n",
    "                        if (Di[m]>=ldd):\n",
    "                            break\n",
    "                        if (m==(len(Di)-1)):\n",
    "                            counts[s,j,Di[m]:] += 1.0\n",
    "                        elif (Di[m+1]>ldd):\n",
    "                            counts[s,j,Di[m]:ldd] += 1.0\n",
    "                        else:\n",
    "                            counts[s,j,Di[m]:Di[m+1]] += 1.0\n",
    "\n",
    "            output[jj,:,:,:] = counts\n",
    "    #counts = output.sum(axis=0)\n",
    "\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Simulate for posterior credibility - treating each set of covariates as independent\n",
    "def posterior_simulator(npat,nboot):\n",
    "\n",
    "    #### Define age indicator variable and add the variable group names\n",
    "    aci = (\n",
    "        (0),\n",
    "        (1),\n",
    "        (2),\n",
    "        (3)\n",
    "        )\n",
    "    anam = (\n",
    "        'Under 26',\n",
    "        '26-50',\n",
    "        '51-75',\n",
    "        'Over 75'\n",
    "    )\n",
    "    distribution = \"weibull\"\n",
    "    na = len(aci) # number of age groups considered\n",
    "\n",
    "    outdict = {x: np.zeros((nboot,na,2)) for x in allowed_transitions}\n",
    "    states_to_start = ['Acute Ward','ICU', 'Recovery Ward']\n",
    "\n",
    "\n",
    "    for j in tqdm(range(0,na)):\n",
    "\n",
    "        kmatb = np.zeros((nstates,nstates))\n",
    "        scalematb = np.zeros((nstates,nstates))\n",
    "\n",
    "        for s in tqdm(range(0,nboot)):\n",
    "            ind = random.randint(0,chain_num*draw_num-1) # random index to sample parameters from posterior distribution\n",
    "            kmatb = np.zeros((nstates,nstates)) \n",
    "            scalematb = np.zeros((nstates,nstates))\n",
    "            othermatb = np.zeros((nstates,nstates))\n",
    "            index_other = aci[j]+8\n",
    "            index_shape = aci[j]+4\n",
    "            index_scale = aci[j]\n",
    "            for k in range(0,ntrans):\n",
    "                \n",
    "                if not global_dist: \n",
    "                    if (k==3 or k==4 or k==5):# If we don't assume a global distribution, fit combination of distributions\n",
    "                        distribution = \"weibull\" # Fit ICU to death and ICU to recovery using Weibull distributions\n",
    "                    else:\n",
    "                        distribution = \"burr\" # Fit remaining transitions using Burr distributions\n",
    "                if (distribution == \"weibull\"):\n",
    "                    ij = np.argwhere(TransNum == (k+1))[0]\n",
    "                    kmatb[ij[0],ij[1]] = (xhats[k,index_shape,ind])\n",
    "                    scalematb[ij[0],ij[1]] = get_scale(xhats[k,index_scale,ind])\n",
    "                    othermatb[ij[0],ij[1]] = float('nan')\n",
    "\n",
    "                if (distribution == \"burr\"):\n",
    "                    ij = np.argwhere(TransNum == (k+1))[0]\n",
    "                    kmatb[ij[0],ij[1]] = (xhats[k,index_shape,ind])\n",
    "                    scalematb[ij[0],ij[1]] = (xhats[k,index_scale,ind])\n",
    "                    othermatb[ij[0],ij[1]] = (xhats[k,index_other,ind])\n",
    "\n",
    "                if not (distribution == \"burr\" or distribution == \"weibull\"):\n",
    "                    print(\"Not fitting correct distribution - please use Weibull or Burr\")\n",
    "                    exit()\n",
    "\n",
    "            for i in range(0,npat):\n",
    "                for ss in states_to_start: # For each patient start in each start state\n",
    "                    y = state_dict[ss]-1\n",
    "\n",
    "                    zz = np.where(Qbase[y,:] > 0.0)[0]\n",
    "                    tti = np.zeros(len(zz))\n",
    "                    yyi = np.zeros(len(zz))\n",
    "                    for q, z in enumerate(zz):\n",
    "                        if np.isnan(othermatb[y,z]): # If transition is given by Weibull\n",
    "                            k = kmatb[y,z]\n",
    "                            scaleg = scalematb[y,z]\n",
    "                            if np.isnan(k):\n",
    "                                tti[q] = float('inf')\n",
    "                            else:\n",
    "                                tti[q] = scaleg*np.random.weibull(k)\n",
    "                            yyi[q] = z\n",
    "                        else:          # If transition is given by Burr\n",
    "                            k = kmatb[y,z]\n",
    "                            scaleg = scalematb[y,z]\n",
    "                            otherp = othermatb[y,z]\n",
    "                            tti[q] = float('inf')\n",
    "                            if np.isnan(k):\n",
    "                                tti[q] = float('inf')\n",
    "                            else:\n",
    "                                tti[q] = st.burr12.rvs(otherp, k, scale = scaleg)\n",
    "                            yyi[q] = z   \n",
    "\n",
    "\n",
    "                    r = np.argmin(tti)\n",
    "\n",
    "                    se = state_names[int(yyi[r])]\n",
    "                    outdict[(ss,se)][s,j,0] += tti[r]\n",
    "                    outdict[(ss,se)][s,j,1] += 1\n",
    "    return(outdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Define required functions - end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Fitting Distributions \n",
    "distribution = \"weibull\" # if using global distribution, set as Weibull or Burr as required\n",
    "\n",
    "\n",
    "ntrans = np.max(TransNum) # Number of transitions to model\n",
    "xhats = np.zeros((ntrans, 15, chain_num*draw_num)) # pre-allocate output variable\n",
    "\n",
    "rsmin = 35 # random seed range. Occasionally first choice may fail to converge, so we can iterate over\n",
    "rsmax = 40 # multiple choices of random seed. Hopefully not needed. \n",
    "\n",
    "for k in tqdm(range(0,ntrans)): # loop over each transition\n",
    "    if not global_dist: \n",
    "        if (k==3 or k==4 or k==5):# If we don't assume a global distribution, fit combination of distributions\n",
    "            distribution = \"weibull\" # Fit ICU to death, ICU to recovery, and recovery to discharge  using Weibull distributions\n",
    "        else:\n",
    "            distribution = \"burr\" # Fit remaining transitions using Burr distributions\n",
    "    \n",
    "    ##### Find data with the transition of interest\n",
    "    dfk = df[df.TransitionNumber == (k+1)]\n",
    "    T = dfk.TimeInState.values\n",
    "    #####\n",
    "    \n",
    "    ##### Remove any zero values (if any - these shouldn't be genuine as there should be a slight delay however small)\n",
    "    jj = T>0. # If we get issues with the lengths not matching up, might be caused here...\n",
    "    T = T[jj] # ...If this is the case, amend data to change any zero durations to 0.1 days and try again.\n",
    "    #####\n",
    "    \n",
    "    ##### Find location of right-censored data points\n",
    "    C = dfk.Observed.values[jj]\n",
    "    D = dfk.Age.values[jj]    \n",
    "    #####\n",
    "    \n",
    "    ##### Define initial conditions and number of variables to fit\n",
    "    'x0 is the initial condition. One set of variable for each set of covariates'\n",
    "    'X is a vector identifying the location of individuals with each set of covariates'\n",
    "    'This is used to determine which variables are fitted to a given individual'\n",
    "    'x is a length indicator for storing the output samples'\n",
    "    if (distribution==\"weibull\"): # If using Weibull\n",
    "        X = np.stack([ (1*(D == 0.0)), (1*(D == 1.0)), \n",
    "                      (1*(D == 2.0)), (1*(D == 3.0))]) \n",
    "        x = 4\n",
    "        \n",
    "    if (distribution==\"burr\"): # If using Burr\n",
    "        X = np.stack([ (1*(D == 0.0)), (1*(D == 1.0)), \n",
    "                      (1*(D == 2.0)), (1*(D == 3.0))])\n",
    "        x = 4\n",
    "        \n",
    "    if not (distribution == \"burr\" or distribution == \"weibull\"):\n",
    "        print(\"Not fitting correct distribution - please use Weibull or Burr\")\n",
    "        exit()\n",
    "    # True / false for censoring (note ~censored captures the full observations)\n",
    "    censored = C == 0\n",
    "       \n",
    "    with pm.Model() as weib_aft_model:        \n",
    "        def weibull_lsf(x, kk, la):\n",
    "            'log survival function for Weibull distribution'\n",
    "            return -(x / la)**kk\n",
    "\n",
    "        def likelihood1(value,kkinput,lainput,ccinput):\n",
    "            'log likelihood for Burr distribution'\n",
    "            c = (ccinput)\n",
    "            k = (kkinput)\n",
    "            l = (lainput)\n",
    "            v1 = c*k/l\n",
    "            v2 = (value/l)**(c-1)\n",
    "            v3 = 1 + (value/l)**c\n",
    "            return pm.math.log(v1*v2*v3**(-k-1)) \n",
    "\n",
    "        def likelihood2(value,kkinput,lainput,ccinput):\n",
    "            'log survival function for Burr distribution'\n",
    "            c = (ccinput)\n",
    "            k = (kkinput)\n",
    "            l = (lainput)\n",
    "            v1 = 1 + (value/l)**c\n",
    "            return -k*pm.math.log(v1)\n",
    "        \n",
    "        if (distribution==\"weibull\"):\n",
    "            ##### Scale parameter comes from a linear combination of parameters with normal priors\n",
    "            beta = pm.Normal('beta', mu=0., sigma=5., shape=x)\n",
    "            la = np.exp(-beta.dot(X))\n",
    "            #####\n",
    "            \n",
    "            ##### Shape parameter prior of exponential\n",
    "            kk = pm.Exponential('kk', lam=1, shape = x)\n",
    "            la2 = kk.dot(X)\n",
    "            #####\n",
    "            \n",
    "            ##### likelihood for censored observations\n",
    "            if len(C)>0:\n",
    "                y_cens = pm.Potential('y_cens', weibull_lsf(T[censored],la2[censored], la[censored]))\n",
    "            #####\n",
    "            \n",
    "            ##### likelihood for observed observations\n",
    "            y_obs = pm.Weibull('y_obs', alpha=la2[~censored], beta=la[~censored], observed=T[~censored])\n",
    "            #####\n",
    "\n",
    "        if (distribution == \"burr\"):\n",
    "            ##### Exponential prior for all parameters\n",
    "            la = pm.Exponential('la', lam=0.2, shape = x)\n",
    "            kk = pm.Exponential('kk', lam=0.2, shape = x)\n",
    "            cc = pm.Exponential('cc', lam=0.2, shape = x)\n",
    "            la2 = la.dot(X)\n",
    "            kk2 = kk.dot(X)\n",
    "            cc2 = cc.dot(X)\n",
    "            #####\n",
    "            \n",
    "            ##### likelihood for censored observations\n",
    "            if len(C)>0:\n",
    "                y_cens = pm.Potential('y_cens', likelihood2(T[censored],kk2[censored], la2[censored], cc2[censored]))           \n",
    "            #####\n",
    "            \n",
    "            ##### likelihood for observed observations\n",
    "            y_obs = pm.Potential('y_obs', likelihood1(T[~censored],kk2[~censored], la2[~censored], cc2[~censored]))\n",
    "            #####\n",
    "\n",
    "    # This sometimes fails with a bad initial energy - resolved through random seed?\n",
    "    # Try resolving through a try and catch.\n",
    "    \n",
    "    rs = rsmin # first random seed attempt\n",
    "    \n",
    "    mcmc_run_ok = False\n",
    "    \n",
    "    while (not mcmc_run_ok) and (rs<rsmax): # if there hasn't been a successful MCMC run, repeat for different random seed\n",
    "        try:\n",
    "            with weib_aft_model:\n",
    "                # Tune and change init to avoid divergences\n",
    "                if saved: # loading saved traces\n",
    "                    trace = pm.load_trace('multistate_trace'+file_date+'_'+str(k+1)+'.trace')\n",
    "                else: # running a new sample\n",
    "                    trace = pm.sample(\n",
    "                        draws=draw_num,\n",
    "                        tune=tune_num,\n",
    "                        target_accept=0.9,\n",
    "                        init='adapt_diag',\n",
    "                        random_seed=rs,\n",
    "                        cores = min((core_num, chain_num)), # numbers of cores needs to be less than or equal to chain_num\n",
    "                        progressbar=True,\n",
    "                        chains = chain_num\n",
    "                    )\n",
    "            mcmc_run_ok = True # after succesful MCMC run change indicator\n",
    "        except:\n",
    "            rs += 1 # move to new random seed if MCMC fails\n",
    "    if (rs < rsmax): # Store output trace into xhats array\n",
    "        if (distribution==\"weibull\"):\n",
    "            xhats[k,0:x,:] = np.transpose(trace.get_values('beta',burn = 0)) # Weibull\n",
    "            xhats[k,x:2*x,:] = np.transpose(trace.get_values('kk',burn = 0)) # Weibull\n",
    "        if (distribution==\"burr\"):\n",
    "            xhats[k,0:x,:] = np.transpose(trace.get_values('la',burn = 0)) # Burr\n",
    "            xhats[k,x:2*x,:] = np.transpose(trace.get_values('kk',burn = 0)) # Burr\n",
    "            xhats[k,2*x:3*x,:] = np.transpose(trace.get_values('cc',burn = 0)) # Burr\n",
    "        if not saved:\n",
    "            pm.save_trace(trace,'multistate_trace'+file_date+'_'+str(k+1)+'.trace',overwrite = True)\n",
    "    else:\n",
    "        print(\"MCMC failed for transition \" + str(k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For transitions that are not observed in the data, set the first parameter to nan. This will cause the simulator to\n",
    "### ignore these transitions\n",
    "print(\"Ensure that you update which age groups go to ICU\")\n",
    "\n",
    "\n",
    "#### For age groups without ICU stays, set ICU transition parameters to NaN\n",
    "if not ICU_0:\n",
    "    xhats[0,0,:] = float('nan')\n",
    "    xhats[3,0,:] = float('nan')\n",
    "    xhats[4,0,:] = float('nan')\n",
    "    xhats[5,0,:] = float('nan')\n",
    "    xhats[0,4,:] = float('nan')\n",
    "    xhats[3,4,:] = float('nan')\n",
    "    xhats[4,4,:] = float('nan')\n",
    "    xhats[5,4,:] = float('nan')\n",
    "if not ICU_1:\n",
    "    xhats[0,1,:] = float('nan')\n",
    "    xhats[3,1,:] = float('nan')\n",
    "    xhats[4,1,:] = float('nan')\n",
    "    xhats[5,1,:] = float('nan')\n",
    "    xhats[0,5,:] = float('nan')\n",
    "    xhats[3,5,:] = float('nan')\n",
    "    xhats[4,5,:] = float('nan')\n",
    "    xhats[5,5,:] = float('nan')\n",
    "if not ICU_2:\n",
    "    xhats[0,2,:] = float('nan')\n",
    "    xhats[3,2,:] = float('nan')\n",
    "    xhats[4,2,:] = float('nan')\n",
    "    xhats[5,2,:] = float('nan')\n",
    "    xhats[0,6,:] = float('nan')\n",
    "    xhats[3,6,:] = float('nan')\n",
    "    xhats[4,6,:] = float('nan')\n",
    "    xhats[5,6,:] = float('nan')\n",
    "if not ICU_3:\n",
    "    xhats[0,3,:] = float('nan')\n",
    "    xhats[3,3,:] = float('nan')\n",
    "    xhats[4,3,:] = float('nan')\n",
    "    xhats[5,3,:] = float('nan')\n",
    "    xhats[0,7,:] = float('nan')\n",
    "    xhats[3,7,:] = float('nan')\n",
    "    xhats[4,7,:] = float('nan')\n",
    "    xhats[5,7,:] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Model fitting - end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Simulations and model output - start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Call the predictions simulator based on two scenarios, exponential growth and constant admissions\n",
    "# Admission rates and numbers need to be added to the function\n",
    "counts_growth_sum = indicative_simulator(1,nboot)\n",
    "counts_constant_sum = indicative_simulator(0,nboot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_growth = counts_growth_sum.sum(axis=0)\n",
    "counts_constant = counts_constant_sum.sum(axis=0)\n",
    "\n",
    "discharge_counts = counts_growth[:,3,:] - np.concatenate([np.zeros((nboot,1)),counts_growth[:,3,:-1]],axis = 1)\n",
    "death_counts = counts_growth[:,4,:] - np.concatenate([np.zeros((nboot,1)),counts_growth[:,4,:-1]],axis = 1)\n",
    "\n",
    "discharge_counts_low = counts_constant[:,3,:] - np.concatenate([np.zeros((nboot,1)),counts_constant[:,3,:-1]],axis = 1)\n",
    "death_counts_low = counts_constant[:,4,:] - np.concatenate([np.zeros((nboot,1)),counts_constant[:,4,:-1]],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sort probabilities of bed occupancies. Generate vector of bed occupancy over time, broken down into weeks. \n",
    "\n",
    "output_acute_med = {}\n",
    "output_acute_high = {}\n",
    "output_icu_med = {}\n",
    "output_icu_high = {}\n",
    "output_rec_med = {}\n",
    "output_rec_high = {}\n",
    "output_discharge_med = {}\n",
    "output_discharge_high = {}\n",
    "output_death_med = {}\n",
    "output_death_high = {}\n",
    "output_acute_low = {}\n",
    "output_icu_low = {}\n",
    "output_rec_low = {}\n",
    "output_discharge_low = {}\n",
    "output_death_low = {}\n",
    "\n",
    "\n",
    "max_len = int((counts_growth.shape[2]-len(census_covariates[:,5]))/7)\n",
    "for x in range(0,max_len):\n",
    "    index = (forecast_start - cur_date).days + 7*(x) + len(census_covariates[:,5])\n",
    "    occupancy_acute = counts_growth[:,0,index]\n",
    "    occupancy_icu = counts_growth[:,1,index]\n",
    "    occupancy_rec = counts_growth[:,2,index]\n",
    "    occupancy_discharge = discharge_counts[:,index]\n",
    "    occupancy_death = death_counts[:,index]\n",
    "    occupancy_acute_low = counts_constant[:,0,index]\n",
    "    occupancy_icu_low = counts_constant[:,1,index]\n",
    "    occupancy_rec_low = counts_constant[:,2,index]\n",
    "    occupancy_discharge_low = discharge_counts_low[:,index]\n",
    "    occupancy_death_low = death_counts_low[:,index]\n",
    "    output_acute_med[x] = np.nanpercentile(occupancy_acute,50)\n",
    "    output_acute_high[x] = np.nanpercentile(occupancy_acute,95)\n",
    "    output_icu_med[x] = np.nanpercentile(occupancy_icu,50)\n",
    "    output_icu_high[x] = np.nanpercentile(occupancy_icu,95)\n",
    "    output_rec_med[x] = np.nanpercentile(occupancy_rec,50)\n",
    "    output_rec_high[x] = np.nanpercentile(occupancy_rec,95)\n",
    "    output_discharge_med[x] = np.nanpercentile(occupancy_discharge,50)\n",
    "    output_discharge_high[x] = np.nanpercentile(occupancy_discharge,95)\n",
    "    output_death_med[x] = np.nanpercentile(occupancy_death,50)\n",
    "    output_death_high[x] = np.nanpercentile(occupancy_death,95)\n",
    "    output_acute_low[x] = np.nanpercentile(occupancy_acute_low,50)\n",
    "    output_icu_low[x] = np.nanpercentile(occupancy_icu_low,50)\n",
    "    output_rec_low[x] = np.nanpercentile(occupancy_rec_low,50)\n",
    "    output_discharge_low[x] = np.nanpercentile(occupancy_discharge_low,50)\n",
    "    output_death_low[x] = np.nanpercentile(occupancy_death_low,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile bed occupancy predictions into a table. Add risk indicator for each bed planning scenario.\n",
    "\n",
    "\n",
    "#### Generate output table for acute beds\n",
    "df_current = [] # preallocate data frame\n",
    "for x in range(0,max_len):\n",
    "    status = []\n",
    "    vect = [output_acute_high[x], output_acute_med[x], output_acute_low[x]]\n",
    "    new_row = [forecast_start +timedelta(x*7), output_acute_high[x], output_acute_med[x], output_acute_low[x]]\n",
    "    df_current.append(new_row)\n",
    "    \n",
    "### Compile table\n",
    "df_output = pd.DataFrame(df_current)\n",
    "df_output.columns = [\"Week\", \"Exponential-case 95%\", \"Exponential-case 50%\", \"Constant-case\"]\n",
    "df_output.to_csv('Output_Acute_'+file_date+'.csv', index = False)\n",
    "###\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "#### Generate output table for ICU beds\n",
    "df_current = [] # preallocate data frame\n",
    "for x in range(0,max_len):\n",
    "    status = []\n",
    "    vect = [output_icu_high[x], output_icu_med[x], output_icu_low[x]]\n",
    "    new_row = [forecast_start +timedelta(x*7), output_icu_high[x], output_icu_med[x], output_icu_low[x]]    \n",
    "    df_current.append(new_row)\n",
    "    \n",
    "### Compile table\n",
    "df_output = pd.DataFrame(df_current)\n",
    "df_output.columns = [\"Week\", \"Exponential-case 95%\", \"Exponential-case 50%\", \"Constant-case\"]\n",
    "df_output.to_csv('Output_ICU_'+file_date+'.csv', index = False)\n",
    "###\n",
    "\n",
    "####\n",
    "\n",
    "#### Generate output table for discharges\n",
    "df_current = [] # preallocate data frame\n",
    "for x in range(0,max_len):\n",
    "    status = []\n",
    "    vect = [output_discharge_high[x], output_discharge_med[x], output_discharge_low[x]]\n",
    "    new_row = [forecast_start +timedelta(x*7), output_discharge_high[x], output_discharge_med[x], output_discharge_low[x]]    \n",
    "    df_current.append(new_row)\n",
    "    \n",
    "### Compile table\n",
    "df_output = pd.DataFrame(df_current)\n",
    "df_output.columns = [\"Week\", \"Exponential-case 95%\", \"Exponential-case 50%\", \"Constant-case\"]\n",
    "df_output.to_csv('Output_discharge_'+file_date+'.csv', index = False)\n",
    "###\n",
    "\n",
    "\n",
    "#### Generate output table for deaths\n",
    "df_current = [] # preallocate data frame\n",
    "for x in range(0,max_len):\n",
    "    status = []\n",
    "    vect = [output_death_high[x], output_death_med[x], output_death_low[x]]\n",
    "    new_row = [forecast_start +timedelta(x*7), output_death_high[x], output_death_med[x], output_death_low[x]]    \n",
    "    df_current.append(new_row)\n",
    "    \n",
    "### Compile table\n",
    "df_output = pd.DataFrame(df_current)\n",
    "df_output.columns = [\"Week\", \"Exponential-case 95%\", \"Exponential-case 50%\", \"Constant-case\"]\n",
    "df_output.to_csv('Output_death_'+file_date+'.csv', index = False)\n",
    "###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Simulations and model output - end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Generate figures - start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Combine age level census into total occupancy\n",
    "#### Define age indicator variable and add the variable group names\n",
    "aci = (\n",
    "    (0),\n",
    "    (1),\n",
    "    (2),\n",
    "    (3)\n",
    "    )\n",
    "anam = (\n",
    "    'Under 26',\n",
    "    '26-50',\n",
    "    '51-75',\n",
    "    'Over 75'\n",
    ")\n",
    "\n",
    "na = len(aci)\n",
    "\n",
    "census = np.zeros((len(census_covariates), nstates + 1))\n",
    "\n",
    "for jj in tqdm(range(0,na)):\n",
    "    census = census + census_covariates[:,jj*(nstates+1):(jj+1)*(nstates+1)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generate axis labels for plotting\n",
    "ld = len(census_covariates)\n",
    "dextra = 50\n",
    "ldd = ld + dextra\n",
    "dayrange = range(1,ldd+1)\n",
    "dt0 = datetime.fromisoformat('2020-03-01 00:00:01')\n",
    "dstart = 0 \n",
    "dd = np.arange(0,ldd,35)\n",
    "#dd = dayrange\n",
    "xl = []\n",
    "for j in range(0,len(dd)):\n",
    "    xl.append((dt0 + timedelta(days=(dstart+int(dd[j])))).strftime('%d/%m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Plot forecasting figures\n",
    "\n",
    "#### PLot growth scenario\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    plt.subplot(2,2,i+1)\n",
    "    for s in range(0,nboot):\n",
    "        plt.plot(dayrange,counts_growth[s,i,:],c='k',linewidth=2,alpha=0.1,zorder=0)  \n",
    "    plt.title(state_names[i])\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Bed Occupancy')\n",
    "    plt.xticks(dd,xl)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "for s in range(0,nboot):\n",
    "    plt.plot(dayrange,np.sum(counts_growth[s,[3,4],:],0),c='k',linewidth=2,alpha=0.1,zorder=0)  \n",
    "plt.title('Outcome')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(dd,xl)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('indicative_growth_'+file_date+'.pdf')\n",
    "\n",
    "#### Plot constant scenario\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    plt.subplot(2,2,i+1)\n",
    "    for s in range(0,nboot):\n",
    "        plt.plot(dayrange,counts_constant[s,i,:],c='k',linewidth=2,alpha=0.01,zorder=0)  \n",
    "    plt.title(state_names[i])\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Bed Occupancy')\n",
    "    plt.xticks(dd,xl)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "for s in range(0,nboot):\n",
    "    plt.plot(dayrange,np.sum(counts_constant[s,[3,4],:],0),c='k',linewidth=2,alpha=0.01,zorder=0)  \n",
    "plt.title('Outcome')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(dd,xl)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('indicative_stable_'+file_date+'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot for comparison with census\n",
    "dayrange = range(0,ldd) #\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    plt.subplot(2,2,i+1)\n",
    "    for s in range(0,nboot):\n",
    "        plt.plot(dayrange,counts_growth[s,i,:],c='k',linewidth=2,alpha=0.1,zorder=0) \n",
    "    z = census[:,i]\n",
    "    w = np.array([])\n",
    "    for day in range(0,len(z)):\n",
    "        w = np.append(w,np.repeat(day, int(z[day])))\n",
    "    t = range(0, len(z))\n",
    "    plt.plot(t, (z), c='w', lw=2, zorder=2)\n",
    "    plt.plot(t, (z), c='r', lw=1, zorder=3)\n",
    "    plt.title(state_names[i])\n",
    "    plt.xlim([0,len(census)+20])\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Bed Occupancy')\n",
    "    plt.xticks(dd,xl)\n",
    "    plt.xticks(rotation=90)\n",
    "plt.subplot(2,2,4)\n",
    "for s in range(0,nboot):\n",
    "    plt.plot(dayrange,np.sum(counts_growth[s,[3,4],:],0),c='k',linewidth=2,alpha=0.1,zorder=0)  \n",
    "z = np.sum(census[:,[3,4]],1)\n",
    "w = np.array([])\n",
    "for day in range(0,len(z)):\n",
    "    w = np.append(w,np.repeat(day, int(z[day])))\n",
    "kde = st.gaussian_kde(w)\n",
    "plt.plot(t, z, c='w', lw=2, zorder=2)\n",
    "plt.plot(t, z, c='r', lw=1, zorder=3)\n",
    "plt.title('Outcome')\n",
    "plt.xlim([0,len(census)+20])\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(dd,xl)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('modelfit_'+file_date+'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Generate figures - end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Generate length of stay estimates - start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Call the posterior simulator to give mean and uncertainty estimates for the observed lengths of stay\n",
    "if (generate_los_estimates == 1):\n",
    "\n",
    "    outdict_sum = posterior_simulator(npat,nboot)\n",
    "\n",
    "    #### Work out probabilities of going to each state and display length of stay and probabilities plus uncertainty\n",
    "\n",
    "    #### Define age indicator variable and add the variable group names\n",
    "    aci = (\n",
    "        (0),\n",
    "        (1),\n",
    "        (2),\n",
    "        (3)\n",
    "        )\n",
    "    anam = (\n",
    "        'Under 26',\n",
    "        '26-50',\n",
    "        '51-75',\n",
    "        'Over 75'\n",
    "    )\n",
    "\n",
    "    na = len(aci) # number of age groups considered\n",
    "    states_to_start = ['Acute Ward','ICU', 'Recovery Ward']\n",
    "\n",
    "    for j in range(0,na):\n",
    "\n",
    "        ss = states_to_start[0]\n",
    "        pvecb = []\n",
    "        prowb  = []\n",
    "        for pair, vec in outdict_sum.items():\n",
    "            if (pair[0] == ss):\n",
    "                prowb.append(outdict_sum[pair][:,j,1])\n",
    "            else:\n",
    "                ss = pair[0]\n",
    "                pvecb.append(prowb)\n",
    "                prowb = []\n",
    "                prowb.append(outdict_sum[pair][:,j,1])\n",
    "        pvecb.append(prowb)\n",
    "\n",
    "        probs = np.array([])\n",
    "        pl = np.array([])\n",
    "        pu = np.array([])\n",
    "        for u in range(0,len(pvecb)):\n",
    "            qa = np.array(pvecb[u])*(100/npat)\n",
    "            qvec = np.nanpercentile(qa,50,1)\n",
    "            ql = np.nanpercentile(qa,2.5,1)\n",
    "            qu = np.nanpercentile(qa,97.5,1)\n",
    "    #         ql = np.nanpercentile(qa,5,1)\n",
    "    #         qu = np.nanpercentile(qa,95,1)\n",
    "            probs = np.concatenate([probs,qvec])\n",
    "            pl = np.concatenate([pl,ql])\n",
    "            pu = np.concatenate([pu,qu])\n",
    "\n",
    "\n",
    "        print('*** {} ***'.format(anam[j]))\n",
    "        u = 0\n",
    "        for pair, vec in outdict_sum.items():\n",
    "            tts = outdict_sum[pair][:,j,0]/outdict_sum[pair][:,j,1]\n",
    "            that = np.nanpercentile(tts,50)\n",
    "            tlow = np.nanpercentile(tts,2.5)\n",
    "            tup = np.nanpercentile(tts,97.5)\n",
    "            print('{} to {}: {:.1f}({:.1f},{:.1f}) days; probability {:.1f}({:.1f},{:.1f})%'.format(\n",
    "                pair[0], pair[1], that, tlow, tup, probs[u], pl[u], pu[u]))\n",
    "            u += 1\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Generate length of stay estimates - end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
